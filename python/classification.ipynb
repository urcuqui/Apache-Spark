{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import DataFrameNaFunctions\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import Binarizer\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer\n",
    "from pyspark import SparkConf, SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster(\"local\").setAppName(\"daily_water_classification\")\n",
    "sc = SparkContext(conf = conf)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = sqlContext.read.load(\"../datasets/daily_weather.csv\", \n",
    "                          format=\"com.databricks.spark.csv\",\n",
    "                          header=True, inferSchema=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|number|\n",
      "+------+\n",
      "|     0|\n",
      "|     1|\n",
      "|     2|\n",
      "|     3|\n",
      "|     4|\n",
      "+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"number\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['number', 'air_pressure_9am', 'air_temp_9am', 'avg_wind_direction_9am', 'avg_wind_speed_9am', 'max_wind_direction_9am', 'max_wind_speed_9am', 'rain_accumulation_9am', 'rain_duration_9am', 'relative_humidity_9am', 'relative_humidity_3pm']\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next list will allow us to define the columns in the weather data that \n",
    "we are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "featureColumns = ['air_pressure_9am',\n",
    " 'air_temp_9am',\n",
    " 'avg_wind_direction_9am',\n",
    " 'avg_wind_speed_9am',\n",
    " 'max_wind_direction_9am',\n",
    " 'max_wind_speed_9am',\n",
    " 'rain_accumulation_9am',\n",
    " 'rain_duration_9am']\n",
    "print(len(featureColumns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"number\") # number is a column that isn't going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.na.drop() # remove all the rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1064, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count(), len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new qualitative variable, let's create to denote if the humidity is not low. If the value is less than 25%, then we want the categorical value to be 0, otherwise the categorical value should be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['air_pressure_9am',\n",
       " 'air_temp_9am',\n",
       " 'avg_wind_direction_9am',\n",
       " 'avg_wind_speed_9am',\n",
       " 'max_wind_direction_9am',\n",
       " 'max_wind_speed_9am',\n",
       " 'rain_accumulation_9am',\n",
       " 'rain_duration_9am',\n",
       " 'relative_humidity_9am',\n",
       " 'relative_humidity_3pm',\n",
       " 'label']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarizer = Binarizer(threshold=24.99999, inputCol=\"relative_humidity_3pm\", outputCol=\"label\")\n",
    "binarizerDF = binarizer.transform(df)\n",
    "binarizerDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----+\n",
      "|relative_humidity_3pm|label|\n",
      "+---------------------+-----+\n",
      "|   36.160000000000494|  1.0|\n",
      "|     19.4265967985621|  0.0|\n",
      "|   14.460000000000045|  0.0|\n",
      "|   12.742547353761848|  0.0|\n",
      "+---------------------+-----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "binarizerDF.select(\"relative_humidity_3pm\", \"label\").show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using VectorAssembler we can aggregate the features that we will use to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[air_pressure_9am: double, air_temp_9am: double, avg_wind_direction_9am: double, avg_wind_speed_9am: double, max_wind_direction_9am: double, max_wind_speed_9am: double, rain_accumulation_9am: double, rain_duration_9am: double, relative_humidity_9am: double, relative_humidity_3pm: double, label: double, features: vector]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assembler = VectorAssembler(inputCols=featureColumns, outputCol=\"features\")\n",
    "assembled = assembler.transform(binarizerDF)\n",
    "assembled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(assembled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = assembled.randomSplit([0.7, 0.3], seed=13234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(742, 322)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData.count(), testData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=5, \n",
    "                            minInstancesPerNode=20, impurity=\"gini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way to train our model is using a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[dt])\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|label|\n",
      "+----------+-----+\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       0.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       0.0|  0.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  0.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  0.0|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"prediction\", \"label\").show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions.select(\"prediction\", \"label\").write.save(path=\"predictions.csv\",\n",
    "#                                                     format=\"com.databricks.spark.csv\",\n",
    "#                                                     header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's load the predictions csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " El volumen de la unidad D es DATOS\n",
      " El nÂ£mero de serie del volumen es: 3449-1924\n",
      "\n",
      " Directorio de D:\\Usuarios\\rhaps\\Documents\\GitHub\\Apache-Spark\\python\n",
      "\n",
      "08/10/2019  09:14 p. m.    <DIR>          .\n",
      "08/10/2019  09:14 p. m.    <DIR>          ..\n",
      "01/10/2019  11:00 p. m.    <DIR>          .ipynb_checkpoints\n",
      "08/10/2019  09:14 p. m.            10.449 classification.ipynb\n",
      "15/09/2019  09:43 p. m.               887 customer-orders.py\n",
      "01/10/2019  11:14 p. m.            21.449 Data Exploration - Pyspark.ipynb\n",
      "15/09/2019  09:43 p. m.             4.400 degrees-of-separation.py\n",
      "15/09/2019  09:43 p. m.               800 friends-by-age.py\n",
      "15/09/2019  09:43 p. m.               946 max-temperatures.py\n",
      "15/09/2019  09:43 p. m.               966 min-temperatures.py\n",
      "15/09/2019  09:43 p. m.             1.001 most-popular-marveleheroe.py\n",
      "15/09/2019  09:43 p. m.             3.712 movie-similarities-1m.py\n",
      "15/09/2019  09:43 p. m.             3.769 movie-similarities.py\n",
      "15/09/2019  09:43 p. m.             1.484 popular-movies-dataframe.py\n",
      "15/09/2019  09:43 p. m.             1.100 popular-movies.py\n",
      "02/10/2019  09:29 p. m.    <DIR>          predictions.csv\n",
      "15/09/2019  09:43 p. m.             1.113 ratings-counter.py\n",
      "15/09/2019  09:43 p. m.             1.150 spark-sql.py\n",
      "15/09/2019  09:43 p. m.             2.176 video_analysis.py\n",
      "15/09/2019  09:43 p. m.             1.426 word-count.py\n",
      "              16 archivos         56.828 bytes\n",
      "               4 dirs  651.233.030.144 bytes libres\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sc)\n",
    "predictions = sqlContext.read.load(\"predictions.csv\", \n",
    "                                  format=\"com.databricks.spark.csv\",\n",
    "                                  header=\"true\",\n",
    "                                  inferSchema=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first two arguments specify the names of the label and prediction columns,\n",
    "# and the last one specifies that we want the overall precision\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", \n",
    "                                             predictionCol=\"prediction\",\n",
    "                                             metricName=\"precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(prediction=1.0, label=1.0), Row(prediction=1.0, label=1.0)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0, 1.0), (1.0, 1.0)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.rdd.map(tuple).take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = MulticlassMetrics(predictions.rdd.map(tuple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[89., 26.],\n",
       "       [19., 85.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusionMatrix().toArray().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.794521\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy = %g\" %(metrics.accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 79\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy = %.2g\" %(metrics.accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
